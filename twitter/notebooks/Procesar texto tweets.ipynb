{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "import re\n",
    "import gc\n",
    "import gensim\n",
    "\n",
    "# from tw_dataset.dbmodels import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('texto_tweets_seguidores_cands') as f:\n",
    "    tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    pre_doc = doc\n",
    "        \n",
    "    # remover URLs\n",
    "    pre_doc = re.sub(\n",
    "        r\"https?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "        \" \", pre_doc)\n",
    "    \n",
    "    # minúsculas\n",
    "    pre_doc = pre_doc.lower()\n",
    "\n",
    "    # volar acentos\n",
    "#     pre_doc = gensim.utils.deaccent(pre_doc)\n",
    "\n",
    "    # remove bullshit\n",
    "    pre_doc = re.sub(r\"\\'|\\\"|\\\\|…|\\/|\\-|\\||\\(|\\)|\\.|\\,|\\!|\\?|\\:|\\;|“|”|’|—\", \" \", pre_doc)\n",
    "    \n",
    "    # contraer vocales\n",
    "    for v in 'aeiou':\n",
    "        pre_doc = re.sub(r\"[%s]+\" % v, v, pre_doc)    \n",
    "\n",
    "    # volar menciones\n",
    "    pre_doc = re.sub(r\"\\@\\w+\",\" \", pre_doc)\n",
    "    \n",
    "    # volar hashtags\n",
    "    pre_doc = re.sub(r\"\\B(\\#[a-zA-Z]+\\b)(?!;)\",\" \", pre_doc)\n",
    "    \n",
    "    # normalizar espacio en blanco\n",
    "    pre_doc = re.sub(r\"\\s+\", \" \", pre_doc)\n",
    "    pre_doc = re.sub(r\"(^\\s)|(\\s$)\", \"\", pre_doc)\n",
    "    \n",
    "    \n",
    "    return pre_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tws = tweets['HectorBaldassi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @carobarbero0830: @actcargentina recorrimos 23000 km con el #caminoalos80 #orgulloTC https://t.co/EXi5rFy9IG\n"
     ]
    }
   ],
   "source": [
    "t = tws[1]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hashtags(t):\n",
    "    return re.findall(r\"\\B(\\#[a-zA-Z]+\\b)(?!;)\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.data import load\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "spanish_tokenizer = load('tokenizers/punkt/spanish.pickle')\n",
    "\n",
    "# stopwords en español\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "# spanish stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "# punctuation to remove\n",
    "non_words = list(punctuation)\n",
    "\n",
    "# we add spanish punctuation\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str, range(10)))\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "def trystem(t):\n",
    "    try:\n",
    "        t = stemmer.stem(t)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return t\n",
    "\n",
    "def tokenize(text, stem=False, remove_stopwords=False):\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    \n",
    "    for sentence in spanish_tokenizer.tokenize(text):\n",
    "        # remover puntuación\n",
    "#         text = ''.join([c for c in sentence if c not in non_words])\n",
    "        \n",
    "        # tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        if remove_stopwords:\n",
    "            tokens = [t for t in tokens if t not in spanish_stopwords]\n",
    "\n",
    "        # tokens de al menos 2 letras\n",
    "        tokens = [t for t in tokens if len(t) > 1]\n",
    "            \n",
    "        # stem\n",
    "        if stem:\n",
    "            tokens = [trystem(t) for t in tokens]\n",
    "        \n",
    "        result += tokens\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class get_docs(object):\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def __iter__(self):\n",
    "        for doc in self.corpus:\n",
    "            tokens = tokenize(preprocess(doc), remove_stopwords=True, stem=False)\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tws = tweets['HectorBaldassi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_tws = list(get_docs(tws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt: 905\n",
      "más: 59\n",
      "si: 56\n",
      "gracias: 55\n",
      "pepsico: 47\n",
      "hoy: 35\n",
      "está: 35\n",
      "breve: 35\n",
      "seguirme: 35\n",
      "macri: 34\n",
      "follow: 34\n",
      "devuelvo: 34\n",
      "vía: 33\n",
      "https: 29\n",
      "justicia: 28\n",
      "argentina: 26\n",
      "vido: 26\n",
      "años: 24\n",
      "silencio: 24\n",
      "paga: 22\n",
      "trabajadores: 21\n",
      "nuevos: 19\n",
      "hacer: 19\n",
      "000: 19\n",
      "gente: 17\n",
      "ahora: 17\n",
      "18: 17\n",
      "hace: 17\n",
      "seguidores: 17\n",
      "país: 17\n",
      "gils: 17\n",
      "gran: 17\n",
      "día: 16\n",
      "dos: 16\n",
      "vez: 16\n",
      "vamos: 16\n",
      "20: 16\n",
      "ser: 16\n",
      "solo: 16\n",
      "santa: 16\n",
      "córdoba: 16\n",
      "3a: 16\n",
      "unfollowers: 15\n",
      "juez: 15\n",
      "trabajo: 15\n",
      "así: 15\n",
      "ley: 15\n",
      "va: 15\n",
      "argentinos: 15\n",
      "millones: 15\n",
      "últimas: 14\n",
      "james: 14\n",
      "cristina: 14\n",
      "cada: 14\n",
      "cfk: 14\n",
      "también: 14\n",
      "gobierno: 13\n",
      "seguir: 13\n",
      "obras: 13\n",
      "agosto: 13\n",
      "http…: 13\n",
      "jueces: 13\n",
      "marihuana: 13\n",
      "qué: 13\n",
      "mejor: 13\n",
      "24h: 12\n",
      "plata: 12\n",
      "ex: 12\n",
      "10: 12\n",
      "15: 12\n",
      "viale910: 12\n",
      "acá: 12\n",
      "https…: 12\n",
      "vos: 12\n",
      "nuevo: 12\n",
      "nueva: 12\n",
      "junto: 12\n",
      "policía: 12\n",
      "cruz: 12\n",
      "puede: 12\n",
      "horas: 11\n",
      "represión: 11\n",
      "massa: 11\n",
      "cómo: 11\n",
      "siempre: 11\n",
      "kirchner: 11\n",
      "12: 11\n",
      "carbó: 11\n",
      "incautamos: 11\n",
      "22: 11\n",
      "marcha: 11\n",
      "izquierda: 11\n",
      "detuvimos: 11\n",
      "presidente: 11\n",
      "tras: 11\n",
      "mil: 11\n",
      "corrupción: 11\n",
      "después: 10\n",
      "lula: 10\n",
      "campaña: 10\n",
      "debe: 10\n",
      "pueden: 10\n",
      "banda: 10\n",
      "50: 10\n",
      "mas: 10\n",
      "mar: 10\n",
      "11: 10\n",
      "será: 10\n",
      "bº: 10\n",
      "d…: 10\n",
      "verdad: 10\n",
      "ón: 10\n",
      "provincia: 10\n",
      "30: 10\n",
      "voy: 10\n",
      "apoyo: 10\n",
      "centro: 10\n",
      "equipo: 10\n",
      "tiempo: 10\n",
      "importante: 10\n",
      "policías: 9\n",
      "julio: 9\n",
      "cambio: 9\n",
      "programa: 9\n",
      "mismo: 9\n",
      "ver: 9\n",
      "vecinos: 9\n",
      "federal: 9\n",
      "sueldos: 9\n",
      "detenidos: 9\n",
      "ciudad: 9\n",
      "meses: 9\n",
      "asi: 9\n",
      "tener: 9\n",
      "queremos: 9\n",
      "dijo: 9\n",
      "heridos: 9\n",
      "quiere: 9\n",
      "prisión: 8\n",
      "fin: 8\n",
      "twets: 8\n",
      "vidal: 8\n",
      "foto: 8\n",
      "bien: 8\n",
      "ir: 8\n",
      "mientras: 8\n",
      "jugador: 8\n",
      "vivo: 8\n",
      "decir: 8\n",
      "villa: 8\n"
     ]
    }
   ],
   "source": [
    "counts = defaultdict(int)\n",
    "\n",
    "for tokens in token_tws:\n",
    "    for t in tokens:\n",
    "        counts[t] += 1\n",
    "\n",
    "# dictionary.filter_extremes(no_below=100, no_above=0.3, keep_n=None)\n",
    "for w, c in sorted(counts.items(), key=lambda x:-x[1])[:150]:\n",
    "    print(\"%s: %d\" % (w, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tws = tweets[\"MartinLlaryora\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtags_cand = [hashtags(preprocess(t)) for t in tws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#belgrano: 9\n",
      "#cba: 9\n",
      "#pepsico: 7\n",
      "#caba: 6\n",
      "#macrireprimepepsico: 5\n",
      "#c: 5\n",
      "#macri: 5\n",
      "#pymes: 4\n",
      "#producci: 4\n",
      "#schiaretti: 4\n",
      "#provincia: 4\n",
      "#instituto: 4\n",
      "#radicales: 4\n",
      "#massismo: 4\n",
      "#cr: 4\n",
      "#campa: 4\n",
      "#nodesalojenpepsico: 4\n",
      "#recursos: 4\n",
      "#cortocircuito: 3\n",
      "#pais: 3\n",
      "#jonathanramis: 3\n",
      "#cambiemos: 3\n",
      "#arg: 3\n",
      "#pretemporadabelgrano: 3\n",
      "#impuestos: 3\n",
      "#ajuste: 3\n",
      "#naci: 2\n",
      "#cgt: 2\n",
      "#empresas: 2\n",
      "#econom: 2\n",
      "#legislativas: 2\n",
      "#devido: 2\n",
      "#decisionempresa: 2\n",
      "#gobiernoupc: 2\n",
      "#criticas: 2\n",
      "#hoy: 2\n",
      "#apoyolaluchadepepsico: 2\n",
      "#consultapopular: 2\n",
      "#puertapuerta: 2\n",
      "#politica: 2\n"
     ]
    }
   ],
   "source": [
    "counts = defaultdict(int)\n",
    "\n",
    "for hts in hashtags_cand:\n",
    "    for ht in hts:\n",
    "        counts[ht] += 1\n",
    "\n",
    "# dictionary.filter_extremes(no_below=100, no_above=0.3, keep_n=None)\n",
    "for w, c in sorted(counts.items(), key=lambda x:-x[1])[:40]:\n",
    "    print(\"%s: %d\" % (w, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
